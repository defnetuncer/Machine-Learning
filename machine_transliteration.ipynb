{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Transliteration\n",
    "Data : https://github.com/steveash/NETransliteration-COLING2018",
    "Hacettepe University Computer Engineering Department",
    "Advisor: Gönenç Ercan",
    "Spring 2018 - Fall 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_language = \"russian\"\n",
    "SUB_LENGTH = 5\n",
    "FREQ = 10\n",
    "\n",
    "wd_train = \"data/wd_\"+target_language+\"_64\"\n",
    "wd_val = \"data/wd_\"+target_language+\"_16\"\n",
    "wd_test = \"data/wd_\"+target_language+\"_20\"\n",
    "wd_dict = \"data/wd_\"+target_language+\"_dict\"\n",
    "wd_train_cos = \"data/wd_\"+target_language+\"_train_cos\"\n",
    "wd_dict_cos = \"data/wd_\"+target_language+\"_dict_cos\"\n",
    "wd_val_transliterate = \"data/wd_\"+target_language+\"_val_transliterate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1 Substring Dictionary based on Cosine Similarities\n",
    "\n",
    "#### \"wd_russian_64\"\n",
    "falla\tф а л ь я\t2\n",
    "- eng = ^falla\\$\n",
    "- target = ^фалья\\$\n",
    "- freq = 2\n",
    "\n",
    "#### \"wd_russian_dict\"\n",
    "- Cosine Similarity is computed for each english_target substring pair\n",
    "- Longest substring is 5 letters long\n",
    "- freq>10\n",
    "\n",
    "eng | target | cos | freq | eng_freq | target_freq\n",
    "--- | --- | --- | --- | --- | ---\n",
    "^f|^ф|0.9263970661836168|16333|16398|18956\n",
    "^fa|^ф|0.27099723439962903|1405|1418|18956\n",
    "^fal|^ф|0.08022706766656275|123|124|18956\n",
    "^fall|^ф|0.0271763212599322|14|14|18956\n",
    "^f|^фа|0.29115061343884335|1428|16398|1467\n",
    "^fa|^фа|0.8583560495795993|1238|1418|1467\n",
    "^fal|^фа|0.2508752846061912|107|124|1467\n",
    "^f|^фал|0.08375619512792033|117|16398|119\n",
    "^fa|^фал|0.2848224813304099|117|1418|119\n",
    "^fal|^фал|0.8808449207803974|107|124|119\n",
    "^f|^фаль|0.07241921027820716|86|16398|86\n",
    "^fa|^фаль|0.2462697730708131|86|1418|86\n",
    "^fal|^фаль|0.774693511983531|80|124|86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectors, vectors_eng, vectors_target = {}, {}, {}\n",
    "for line in open(wd_train, encoding='utf8'):\n",
    "    line = line.split()\n",
    "    eng = \"^\" + line[0] + \"$\"\n",
    "    target = \"^\" + \"\".join(line[1:-1]) + \"$\"\n",
    "    freq = int(line[-1])\n",
    "    sub_eng = []\n",
    "    for i in range(1, len(eng)-1):\n",
    "        for j in range(i, len(eng)-1):\n",
    "            if j-i > SUB_LENGTH: continue\n",
    "            elif i==1:\n",
    "                if j==len(eng)-2: sub = eng[i-1::]\n",
    "                else: sub = eng[i-1:j+1]\n",
    "            elif j==len(eng)-2: sub = eng[i::]\n",
    "            else: sub = eng[i:j+1]\n",
    "            sub_eng.append(sub)\n",
    "            if sub not in vectors_eng: vectors_eng[sub] = freq\n",
    "            else: vectors_eng[sub] += freq\n",
    "        \n",
    "    for i in range(1, len(target)-1):\n",
    "        for j in range(i, len(target)-1):\n",
    "            if j-i > SUB_LENGTH: continue\n",
    "            elif i == 1:\n",
    "                if j==len(target)-2: sub = target[i-1::]\n",
    "                else: sub = target[i-1:j+1]\n",
    "            elif j==len(target)-2: sub = target[i::]\n",
    "            else: sub = target[i:j+1]\n",
    "            if sub not in vectors_target: vectors_target[sub] = freq\n",
    "            else: vectors_target[sub] += freq\n",
    "            \n",
    "            for e in sub_eng:\n",
    "                eng_target = e + \"_\" + sub\n",
    "                if eng_target.count(\"^\")!=1 and eng_target.count(\"$\")!=1:\n",
    "                    if eng_target not in vectors: vectors[eng_target] = freq\n",
    "                    else: vectors[eng_target] += freq\n",
    "        \n",
    "out = open(wd_dict, \"w+\", encoding=\"utf8\")\n",
    "for sub, freq in vectors.items():\n",
    "    eng = vectors_eng.get(sub.split(\"_\")[0])\n",
    "    target = vectors_target.get(sub.split(\"_\")[1])\n",
    "    cos = freq/np.sqrt(eng*target)\n",
    "    if freq>FREQ:\n",
    "        out.write(sub+\",\"+str(cos)+\",\"+str(freq)+\",\"+str(eng)+\",\"+str(target)+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Partition\n",
    "\n",
    "`partition_list = partition(\"falla\", len(\"falla\"))`\n",
    "\n",
    "1 | 2 | 3 | 4 | 5\n",
    "--- | --- | --- | --- | --- \n",
    "^falla\\$ | ^fall_a\\$ | ^fal_l_a\\$ | ^fa_l_l_a\\$ | ^f_a_l_l_a\\$\n",
    "- | ^fa_lla\\$  | ^fa_ll_a\\$ | ^f_al_l_a\\$ | -\n",
    "- | ^fal_la\\$ | ^fa_l_la\\$ | ^f_a_ll_a\\$ | -\n",
    "- | ^fa_lla\\$ | ^f_all_a\\$ | ^f_a_l_la\\$ | -\n",
    "- | ^f_alla\\$ | ^f_al_la\\$ | - | -\n",
    "- | - | ^f_a_lla\\$ | - | -\n",
    "     \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(word, max_len):\n",
    "    partition_list = [[] for i in word]\n",
    "    matrix = [[] for i in word]\n",
    "    \n",
    "    for i in range(0, len(word)):\n",
    "        for j in range(i, len(word)):\n",
    "            if j<=i+SUB_LENGTH:\n",
    "                matrix[i].append(word[i:j+1])    \n",
    "                    \n",
    "    stack = [i for i in matrix[0]]\n",
    "    top = len(stack)-1\n",
    "    \n",
    "    while top!=-1:\n",
    "        temp = stack[top]\n",
    "        templen = len(temp) - len(temp.split(\"_\"))+1\n",
    "        if templen == len(word):\n",
    "            partition_list[len(temp.split(\"_\"))-1].append(\"^\"+temp+\"$\")\n",
    "        else:\n",
    "            for i in matrix[templen]:\n",
    "                if len(stack) > top:\n",
    "                    stack[top] = temp + \"_\" + i\n",
    "                    top+=1\n",
    "                else:\n",
    "                    stack.append(temp + \"_\" + i)\n",
    "                    top+=1\n",
    "        top-=1    \n",
    "    return partition_list[0:max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "#### \"wd_russian_train_cos\"\n",
    "target | english | best split score\n",
    "--- | --- | ---\n",
    "^ф\\_а\\_л\\_ья\\$|^f\\_a\\_l\\_la\\$|0.8732937987793205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cos_dict = {}\n",
    "for line in open(wd_dict, encoding='utf8'):\n",
    "    line = line.strip().split(\",\")\n",
    "    cos_dict[line[0]] = [i for i in map(float,line[1::])]\n",
    "    \n",
    "out = open(\"za\", \"w+\", encoding=\"utf8\")\n",
    "count = 0\n",
    "for line in open(wd_train, encoding='utf8'):\n",
    "    count += 1\n",
    "    line = line.split()\n",
    "    eng, target, freq = line[0], \"\".join(line[1:-1]), int(line[-1])\n",
    "    best, best_target, best_eng = 0.0, \"\", \"\"\n",
    "    \n",
    "    max_len = min(len(eng),len(target))\n",
    "    eng_list = partition(eng,max_len)\n",
    "    target_list = [i for j in partition(target,max_len) for i in j]\n",
    "    for t in target_list:\n",
    "        t_arr = t.split(\"_\")\n",
    "        for e in eng_list[len(t_arr)-1]:\n",
    "            score = 0.0\n",
    "            e_arr = e.split(\"_\")\n",
    "            for i in range(len(t_arr)):\n",
    "                key = e_arr[i] + \"_\" + t_arr[i]\n",
    "                if key in cos_dict: score += cos_dict.get(key)[0]\n",
    "        score /= len(t_arr)\n",
    "        if score > best:\n",
    "            best = score\n",
    "            best_eng = e\n",
    "            best_target = t\n",
    "    out.write(best_target + \",\" + best_eng + \",\" + str(best) + \"\\n\")    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2 Substring Dictionary based on Trained Data\n",
    "\n",
    "#### \"wd_russian_dict_cos\"\n",
    "\n",
    "- Cosine Similarity is computed for each english_target substring pair\n",
    "- freq>10\n",
    "\n",
    "eng | target | cos | freq | eng_freq | target_freq\n",
    "--- | --- | --- | --- | --- | ---\n",
    "^f|^ф|0.9472872369467044|1253|1350|1296\n",
    "a|а|0.9143036189080495|19407|21246|21206\n",
    "l|л|0.9086893873798547|7987|9019|8566\n",
    "la\\$|ья\\$|0.3561381495309969|11|18|53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectors, vectors_eng, vectors_target = {}, {}, {}\n",
    "for line in open(wd_train_cos, encoding='utf8'):\n",
    "    line = line.split(\",\")\n",
    "    target = line[0].split(\"_\")\n",
    "    eng = line[1].split(\"_\")\n",
    "    score = float(line[2])\n",
    "    for i in range(len(target)):\n",
    "        if eng[i] not in vectors_eng: vectors_eng[eng[i]] = 1\n",
    "        else: vectors_eng[eng[i]] += 1\n",
    "        if target[i] not in vectors_target: vectors_target[target[i]] = 1\n",
    "        else: vectors_target[target[i]] += 1\n",
    "        key = eng[i] + \"_\" + target[i]\n",
    "        if key not in vectors: vectors[key] = 1\n",
    "        else: vectors[key] += 1\n",
    "\n",
    "out = open(wd_dict_cos, \"w+\", encoding=\"utf8\")\n",
    "for sub, freq in vectors.items():\n",
    "    eng = vectors_eng.get(sub.split(\"_\")[0])\n",
    "    target = vectors_target.get(sub.split(\"_\")[1])\n",
    "    cos = freq/np.sqrt(eng*target)\n",
    "    if freq>FREQ:\n",
    "        out.write(sub+\",\"+str(cos)+\",\"+str(freq)+\",\"+str(eng)+\",\"+str(target)+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "#### \"wd_russian_val_transliterate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate(word,target):\n",
    "    word_list = [i for j in partition(word,len(word)) for i in j]\n",
    "    best = [0.0,0.0,0.0]\n",
    "    best_target = [[],[],[]]\n",
    "    best_word = [[],[],[]]\n",
    "    for w in word_list:\n",
    "        w_arr = w.split(\"_\")\n",
    "        score = 0.0\n",
    "        match = []\n",
    "        for p in w_arr:\n",
    "            if p in target_dict:\n",
    "                match.append(target_dict.get(p))\n",
    "                score+=score_dict.get(p)\n",
    "            else:\n",
    "                score = 0.0\n",
    "                break\n",
    "        score/=len(w_arr)\n",
    "        minimum = min(best)\n",
    "        if score>minimum:\n",
    "            index = best.index(minimum)\n",
    "            best[index]=score\n",
    "            best_target[index] = match\n",
    "            best_word[index] = w_arr\n",
    "    \n",
    "    bests = [\"\".join(i)[1:-1] for i in best_target]\n",
    "    if bests[0] == target:\n",
    "        score=1\n",
    "        out.write(\"\\n + \")\n",
    "    elif bests[1] == target:\n",
    "        score=2\n",
    "        out.write(\"\\n + \")\n",
    "    elif bests[2] == target:\n",
    "        score=3\n",
    "        out.write(\"\\n + \")\n",
    "    else:\n",
    "        score=0\n",
    "        out.write(\"\\n - \")\n",
    "    out.write(word + \"->\" + target + \"\\n________\\n\")\n",
    "    [out.write(i + \"    \") for i in bests]\n",
    "    out.write(\"\\n--------\\n\")\n",
    "    [out.write(\"_\".join(i)+\"    \") for i in best_target]\n",
    "    out.write(\"\\n\")\n",
    "    [out.write(\"_\".join(i)+\"    \") for i in best_word]\n",
    "    out.write(\"\\n\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate_eng_to_target():\n",
    "    for line in open(wd_dict_cos, encoding='utf8'):\n",
    "        line = line.strip().split(\",\")\n",
    "        eng_target = line[0].split(\"_\")\n",
    "        if eng_target[0] not in target_dict:\n",
    "            target_dict[eng_target[0]] = eng_target[1]\n",
    "            score_dict[eng_target[0]] = float(line[1])\n",
    "        elif score_dict.get(eng_target[0])<float(line[1]):\n",
    "            target_dict[eng_target[0]] = eng_target[1]\n",
    "            score_dict[eng_target[0]] = float(line[1])\n",
    "    best = [0,0,0,0]\n",
    "    for line in open(wd_val, encoding='utf8'):\n",
    "        line = line.split()\n",
    "        eng = line[0]\n",
    "        target = \"\".join(line[1:-1])\n",
    "        best[transliterate(eng, target)]+=1\n",
    "    return best\n",
    "        \n",
    "def transliterate_target_to_eng():\n",
    "    for line in open(wd_dict_cos, encoding='utf8'):\n",
    "        line = line.strip().split(\",\")\n",
    "        eng_target = line[0].split(\"_\")\n",
    "        if eng_target[1] not in target_dict:\n",
    "            target_dict[eng_target[1]] = eng_target[0]\n",
    "            score_dict[eng_target[1]] = float(line[1])\n",
    "        elif score_dict.get(eng_target[1])<float(line[1]):\n",
    "            target_dict[eng_target[1]] = eng_target[0]\n",
    "            score_dict[eng_target[1]] = float(line[1])\n",
    "    best = [0,0,0,0]\n",
    "    for line in open(wd_val, encoding='utf8'):\n",
    "        line = line.split()\n",
    "        eng = line[0]\n",
    "        target = \"\".join(line[1:-1])\n",
    "        best[transliterate(target, eng)]+=1\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 1:  0.3360792650520082\n",
      "Best 2:  0.4361096348037355\n",
      "Best 3:  0.4421076607698732\n"
     ]
    }
   ],
   "source": [
    "target_dict = {}\n",
    "score_dict = {}\n",
    "out = open(\"za\", \"w+\", encoding=\"utf8\")\n",
    "best = transliterate_eng_to_target()\n",
    "\n",
    "total = sum(best)\n",
    "best1 = best[1]\n",
    "best2 = best[1]+best[2]\n",
    "best3 = best[1]+best[2]+best[3]\n",
    "\n",
    "print(\"Best 1: \", best1/total)\n",
    "print(\"Best 2: \", best2/total)\n",
    "print(\"Best 3: \", best3/total)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- While training include 3 best splits into dictionary - scores can also be useful ?\n",
    "- Most of the tests don't even have 3 splits (insufficient dictionary ? - freq>10 ?)\n",
    "- At step #1 Extracting freq<10 pairs results one-to-one matches\n",
    "\n",
    "target | eng\n",
    "--- | ---\n",
    "сисвомихарджо | siswomiharjo\n",
    "^с\\_и\\_с\\_в\\_о\\_м\\_и\\_х\\_а\\_р\\_дж\\_о\\$ | ^s_i_s_w_o_m_i_h_a_r_j_o\\$    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
